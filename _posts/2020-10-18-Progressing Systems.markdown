---
layout: post
title:  Progressing Systems
date:   2020-10-18 18:19:00 -0700
categories: blog
tags: test
---

Most of the progress we make as a civilization is carried forward through our systems. They aren't all designed with conscious intent, but they do all change and impact our lives in different ways. Certain actions and thoughts become easier for us to do, and some others become more difficult. 

For example, it's easier today for me to use search engines to find answers to embarrassing or trivial (by my perceived social standards) personal problems than it would have been 30 years ago. Aside from the fact that I wouldn't have been alive 30 years ago, I'd have had to go to a library or find some other way to research the subject. More likely I would have just accepted the existence of most of those problems until they grew too large to tolerate and I got fed up and asked someone for advice.  

Search engines (and more broadly the internet) have changed many aspects of our lives, and they've changed vast swaths of behaviour. Many systems also just make certain things easier, and thus make us more likely to do them: being able to automate financial transactions monthly enables people to save or invest without having to make a conscious decision every month or year. The option existing isn't the end of the story though. People improve the systems over time to make them easier to use, higher quality, more worthy of trust and so on, enabling more and more people to actually take action and change their lives. Other small examples include spell-checking systems in Email and Word processors, or the growing popularity of grammar tools like Grammarly. 

When looking for ways to improve our lives individually, there are plenty of existing systems out there that we could research and try out. Our digital and mental lives are more connected than ever, and we can leverage that to automate certain parts of our lives. Every system is an investment of some sort, whether it's an investment of time and learning now for benefits later, or an investment of signing up for some initial discomfort to see where things may go. It might not work out, but trying to make only risk-free decisions is not nearly as effective as taking some small risks and learning from the outcomes.

To start, I've been looking out for patterns in my behaviour. If something shows up repeatedly, I start to dig into figuring out what systematic changes I could make to change it in some desirable way. If I consistently end up sleeping later than I'd like, and I notice that's because I put off writing my daily blog post at the end of the day... Then that realization has a dual benefit: I can experiment with writing earlier in the day and seeing how that helps my sleep, and it also puts me face to face with the uncomfortable reality that I'm avoiding writing and that that's another system I'll want to work on analyzing. For a lot of this stuff, it seems like building the skill to simply observe and analyze without feeling bad is inherently valuable itself. Even if I make no changes to the systems soon, simply looking at them repeatedly and introspecting on why there's difficulty being honest with myself is progress. 

I've also found it interesting to consider what the intent of any system I'm in is. That grocery store, how is it designed? Which choices is it making easy for me and which choices is it making difficult? How am I interacting with it in a way that gets me closer to what I want? That interaction with a banking clerk, or that browsing experience of a blog or website like Amazon/Google/Netflix. The more I use a website, the more unaware I tend to become of how its design works and how I'm interacting with it. It just becomes habitual and automated. Intentionally looking back at noticing those things while I'm interacting with software or people or physical environments (they're all systems) helps me get out of my own perspective and consider how other people might be looking at things too. 

One nice thing is that most well designed systems make it easy for the participant to get what they want (and benefit the creators of the system in some way usually) without sacrifice from either end of the participation. Sometimes the benefit to the creators is simply knowing that they made someone's life better. Well designed systems also make it easy for the participant to learn that they can't get what they want here, and that they should spend their time and energy elsewhere. The quicker a participant can find that out-- And the less friction and tension they have to go through as they exit the system --the better off the participants are. Not every system creator wants to build systems that maximize what's best for the participants and their goals, but I think those are some of the systems with the greatest long-term potential. If people continue to learn about shady and manipulative design practices for systems, they'll simply go elsewhere as demand is created for alternative, more consumer-friendly systems. Ultimately systems might have pushy salespeople or prompts to donate to charity because those things work. But we get to pay attention and decide for ourselves what we care about and prioritize those things. 

Progress can be broader than we usually think, and the starting point is wherever we choose to change something in how we think. A change can can simply be choosing to observe something more or look at the potential links between our daily behaviour and patterns of responding to certain kinds of situations. We can be wrong about what we notice, but as long as we're open to revising what we notice, we can keep making progress towards better systems. 


























